{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based upon **08 pandas**, so please make sure you run and understood that one.<br>\n",
    "This notebook will scratch on the surface of machine learning by introducing some techniques and algorithms. The idea and application of the objects representing the algorithms is demonstrated. Your task will be to beat the presented, dramatically simplified algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scipy stack includes the scikit-learn module which covers anything one would need for solving everyday machine learning tasks. The basic idea is usually to *train* a pure data-driven algorithm on a *training dataset*. This dataset includes different *predictors* that are used to predict the state or value of a *target* variable. After training the algorithm, it will be applied to a *test dataset* in order to rate its performance. Usually, the predicting accuracy is used as a measure.<br>\n",
    "Before data can be handed to an algorithm it has to be preprocessed to make the algorithm classes understand the data in a correct way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from pprint import pprint\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>LoanAmountMedian</th>\n",
       "      <th>ApplicantIncomeMedian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001011</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LP001013</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2333</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LP001014</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>3+</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3036</td>\n",
       "      <td>2504.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LP001018</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4006</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LP001020</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>12841</td>\n",
       "      <td>10968.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LP001024</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3200</td>\n",
       "      <td>700.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID  Gender  Married Dependents  Education  Self_Employed  \\\n",
       "0  LP001003      -1     True          1       True          False   \n",
       "1  LP001005      -1     True          0       True           True   \n",
       "2  LP001006      -1     True          0      False          False   \n",
       "3  LP001008      -1    False          0       True          False   \n",
       "4  LP001011      -1     True          2       True           True   \n",
       "5  LP001013      -1     True          0      False          False   \n",
       "6  LP001014      -1     True         3+       True          False   \n",
       "7  LP001018      -1     True          2       True          False   \n",
       "8  LP001020      -1     True          1       True          False   \n",
       "9  LP001024      -1     True          2       True          False   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             4583             1508.0       128.0             360.0   \n",
       "1             3000                0.0        66.0             360.0   \n",
       "2             2583             2358.0       120.0             360.0   \n",
       "3             6000                0.0       141.0             360.0   \n",
       "4             5417             4196.0       267.0             360.0   \n",
       "5             2333             1516.0        95.0             360.0   \n",
       "6             3036             2504.0       158.0             360.0   \n",
       "7             4006             1526.0       168.0             360.0   \n",
       "8            12841            10968.0       349.0             360.0   \n",
       "9             3200              700.0        70.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  LoanAmountMedian  \\\n",
       "0            True         Rural           N             False   \n",
       "1            True         Urban           Y             False   \n",
       "2            True         Urban           Y             False   \n",
       "3            True         Urban           Y              True   \n",
       "4            True         Urban           Y              True   \n",
       "5            True         Urban           Y             False   \n",
       "6           False     Semiurban           N              True   \n",
       "7            True         Urban           Y              True   \n",
       "8            True     Semiurban           N              True   \n",
       "9            True         Urban           Y             False   \n",
       "\n",
       "   ApplicantIncomeMedian  \n",
       "0                   True  \n",
       "1                  False  \n",
       "2                  False  \n",
       "3                   True  \n",
       "4                   True  \n",
       "5                  False  \n",
       "6                  False  \n",
       "7                   True  \n",
       "8                   True  \n",
       "9                  False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the file from last week (08 pandas)\n",
    "df = pd.read_csv('data/train_corrected.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can continue, we have to split the dateset into the predictors and the target values. In the language of machine learning you call them *data* and *target*. In this example, we will only use the Gender and Education predictors for a first guess. Trying to beat an algorithm based only on that data, you'll have to redo all these steps with your predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = df.Loan_Status.values\n",
    "data = df[['Gender', 'Education', 'Self_Employed']].values\n",
    "assert len(target) == len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing toolbox offers sever classes that can convert labels and ranges to data, that the algorithms actually understand. Both datasets hold binary information, therefore the Binarizer class is the correct one. Parameters are always given to the objects on instantiation. Before the input can be transformed (e.g. into a binary information), the Transformer has to be fitted to the input data. Most classes offer a fit_transform method, that can do both steps in one.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = preprocessing.Binarizer().fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use any of the predictors, we should check the correlations between the predictors. There is no sense in using two highly correlated predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.50000000000000011, pvalue=0.66666666666666674)\n",
      "(0.5, 0.66666666666666663)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "print(spearmanr(data[0], data[1]))\n",
    "print(pearsonr(data[0], data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable holds Label information. We can use the LabelEncoder to turn the labels into integer. Here, we could also use the Binarizer, as there are only two different target classes. Nevertheless, the LabelEncoder can work on more than two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = preprocessing.LabelEncoder().fit_transform(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need an test and a train dataset. In this very specific case we downloaded only the train dataset last week and could now download the test.csv as well. Then you would have to apply the cleanup to the test dataset in exactly the same way. Nevertheless scikit-learn offers a convenient function to split data into a test and a train dataset: *train_test_split*. In the machine learning world, the data would be denoted as a captial X and the target as a lower y. Usually you would split into $\\frac{1}{3}$ test and $\\frac{2}{3}$ train size, but the function can take any ratio you need. Lastly, a random state can be used as a seed to randomly choose the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (328, 3)\n",
      "Test data: (162, 3)\n",
      "Train targets: (328,)\n",
      "Test targets: (162,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=1337)\n",
    "print('Train data:', X_train.shape)\n",
    "print('Test data:', X_test.shape)\n",
    "print('Train targets:', y_train.shape)\n",
    "print('Test targets:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will use one of the easiest algorithms for predicting the Loan Status: the Decision Tree. A decision tree will build up different branches of sucessive decisions (nodes, or here: leafs) based on all predictor combinations to reach the target classes. That means decision trees are classifiers, exactly what we need. It will answer a question represented by one leaf based on the state of the actual dataset until it reaches a target leaf.<br>\n",
    "One important parameter for decision trees is the break criterion. You can specify in many ways, when the algortihm shall stop building branches and leafs and add the targets. If it wouldn't stop, it might create one branch for each unique dataset (with as many leafs as there are predictor combinations making this data point unique). This would be overfitting, as it is 100% accurate on the train dataset but most likely very bad on test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can now either set the maximum length (depth) of branches (*max_depth*), the minimum samples that have to pass a leaf (*min_samples_leaf*) or the minimum samples needed on a node to actually split it into a new branch (*min_samples_split*). min_samples_leaf defaults to 1 and min_samples_split defaults to 2. This would result leafs, that are only entered by two data points, where each of them using another branch. <br>\n",
    "Often it is a good choice to set a max_depth and increment this number by validating that no overfitting took place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64814814814814814"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# instantiate a Decision Tree\n",
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=3)\n",
    "\n",
    "# build the tree based upon the test samples\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the test datset\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result we had above is highly dependend on the splitting we made. Generally, a machine learning algorithm is better, when the test dataset contains all value ranges and predictor combination that are possible. Or at least preset in the test dataset. With an easy Decision Tree like the one we used, the predictions will turn into prediction always '1', if we use not enough predictors or unsuitable training dataset sizes. Remind, that we find more '1's in the target than '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([154, 336])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(target, bins=2)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remove the random_state from train_test_split and rerun the splitting and prediction several times, you will notice, that the accuracy changes by about 10%! A better way to get a more splitting-independent score is to use k-fold cross validation.<br>\n",
    "Here, the dataset is splitted into $k$ slices (here called folds). The the Decision Tree is trained with $k -1$ folds and tested on the remaining fold. The score is then the mean score of all runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3-Fold accuracy: 68.4%\n",
      " 5-Fold accuracy: 68.8%\n",
      " 7-Fold accuracy: 68.8%\n",
      "10-Fold accuracy: 68.2%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score   # for scoring\n",
    "from sklearn.model_selection import cross_val_predict # for predicting\n",
    "\n",
    "# build the decision tree\n",
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# 5-fold cross validation\n",
    "print(' 3-Fold accuracy: %.1f%%' % (cross_val_score(clf, data, target, cv=3).mean() * 100))\n",
    "print(' 5-Fold accuracy: %.1f%%' % (cross_val_score(clf, data, target, cv=5).mean() * 100))\n",
    "print(' 7-Fold accuracy: %.1f%%' % (cross_val_score(clf, data, target, cv=7).mean() * 100))\n",
    "print('10-Fold accuracy: %.1f%%' % (cross_val_score(clf, data, target, cv=10).mean()* 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is actually another weakness in the model. Beside the dependance on the folds / test dataset, there is also a dependancy on the distribution of the classes. The 'Y' class is overweighting the 'N' by far. Both weaknesses can be overcome to a specific amount by the RandomForest algorithm.<br>\n",
    "As the name is already stating, a RandomForest is a set of DecisionTrees. Here, a subset of data is choosen from the dataset and passed to a number of DecisionTrees. Overfitting and mean accuracy are then improved by using the average tree performance. The scipy RandomForest can also bootstrap the sub-samples, that means the data points are drawn from the dataset with repetitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64814814814814814"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(criterion='entropy', n_estimators=10, max_depth=3, \n",
    "                             bootstrap=True, max_features='auto')\n",
    "\n",
    "# fit the forest\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are slightly better than the Decision tree on its own. You could try to adapt some of the settings to see the influence on the result. Of course we can again cross-validate the RandomForest like we did with the DecisionTree. \n",
    "Now, we would need a suitable test scenario, altering only one of the parameters at a time or doing a sensitivity analysis, over blind-guessing good parameter choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3-Fold accuracy: 68.8%\n",
      " 5-Fold accuracy: 68.8%\n",
      " 7-Fold accuracy: 68.4%\n",
      "10-Fold accuracy: 68.2%\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(criterion='entropy', n_estimators=50, max_depth=3, \n",
    "                             bootstrap=True, max_features='auto')\n",
    "\n",
    "print(' 3-Fold accuracy: %.1f%%' % (cross_val_score(clf, data, target, cv=3).mean() * 100))\n",
    "print(' 5-Fold accuracy: %.1f%%' % (cross_val_score(clf, data, target, cv=5).mean() * 100))\n",
    "print(' 7-Fold accuracy: %.1f%%' % (cross_val_score(clf, data, target, cv=7).mean() * 100))\n",
    "print('10-Fold accuracy: %.1f%%' % (cross_val_score(clf, data, target, cv=10).mean()* 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there is nothing we can do to improve a RandomForest or DecisionTree based on only these 3 predictors.<br><br>\n",
    "<div class=\"alert alert-success\"><br>**TASK:** Now it's your turn! beat my 68.8% accuracy!<br><br></div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3-dev]",
   "language": "python",
   "name": "conda-env-py3-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
